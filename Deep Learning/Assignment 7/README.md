# Deep Learning – Assignment 7: Autoencoders and Variational Autoencoders

## Table of Contents
- [Deep Learning – Assignment 7: Autoencoders and Variational Autoencoders](#deep-learning--assignment-7-autoencoders-and-variational-autoencoders)
  - [Table of Contents](#table-of-contents)
  - [Overview](#overview)
  - [Objectives](#objectives)
  - [Implemented Models](#implemented-models)
    - [Standard Autoencoder](#standard-autoencoder)
    - [Denoising Autoencoder (DAE)](#denoising-autoencoder-dae)
    - [Variational Autoencoder (VAE)](#variational-autoencoder-vae)
  - [Methodology](#methodology)
    - [Data Preprocessing](#data-preprocessing)
    - [Model Architectures](#model-architectures)
    - [Training Procedures](#training-procedures)
  - [Results \& Visualizations](#results--visualizations)

---

## Overview
In **Assignment 7**, we implement and compare several types of autoencoder architectures to learn efficient, low-dimensional representations of data. The project includes three distinct models:
1. A Standard Autoencoder that compresses and reconstructs input data.
2. A Denoising Autoencoder (DAE) that learns to recover clean inputs from corrupted versions.
3. A Variational Autoencoder (VAE) that models a probabilistic latent space for generative tasks.

---

## Objectives
- Understand the fundamentals of unsupervised representation learning using autoencoders.
- Compare reconstruction quality and latent space characteristics between standard, denoising, and variational autoencoders.
- Evaluate model performance using reconstruction loss and qualitative analysis of generated outputs.
- Explore the potential for using VAEs in generative modeling and data synthesis.

---

## Implemented Models

### Standard Autoencoder
- **Description**: Compresses input data into a latent representation and reconstructs the original input.
- **Implementation**: 
  - Built using a simple feed-forward neural network.
  - Consists of an encoder network that reduces dimensionality and a decoder network that reconstructs the input.
- **Notebook**: `1_autoencoders.ipynb`

---

### Denoising Autoencoder (DAE)
- **Description**: Learns robust representations by reconstructing the original, clean input from a corrupted version.
- **Implementation**: 
  - Adds noise to input data during training.
  - Trains the model to remove noise and recover the underlying signal.
- **Notebook**: `2_dae.ipynb`

---

### Variational Autoencoder (VAE)
- **Description**: A generative model that learns a probabilistic latent space, allowing for the generation of new data samples.
- **Implementation**: 
  - The encoder outputs parameters (mean and variance) of a latent Gaussian distribution.
  - Utilizes the reparameterization trick to enable backpropagation through stochastic sampling.
  - The loss function combines reconstruction loss with a KL divergence term to regularize the latent space.
- **Notebook**: `3_vae.ipynb`

---

## Methodology

### Data Preprocessing
- Load and normalize the dataset.
- Convert the data into a suitable format for training (e.g., NumPy arrays or PyTorch tensors).
- (For the DAE) Introduce controlled noise to the input data during training.

### Model Architectures
- **Standard Autoencoder**: Implements basic encoder and decoder layers using fully connected networks.
- **Denoising Autoencoder**: Mirrors the standard autoencoder but with an added noise injection step at the input.
- **Variational Autoencoder**: Uses an encoder that outputs latent distribution parameters and a decoder that reconstructs input from sampled latent vectors.

### Training Procedures
- Train each model using a reconstruction loss (typically Mean Squared Error for continuous data).
- For the VAE, include a KL divergence term in the loss function to enforce a Gaussian prior on the latent space.
- Use optimizers such as Adam and tune hyperparameters (learning rate, batch size, number of epochs) for optimal performance.
- Monitor training progress via loss curves and validation performance.

---

## Results & Visualizations
- **Reconstruction Quality**: Visual comparisons between original inputs and reconstructions from each model.
- **Latent Space Analysis**: (Optional) Use t-SNE or PCA to visualize the latent representations learned by the VAE.
- **Loss Curves**: Training and validation loss plots demonstrating convergence for each model variant.
- **Generated Samples (VAE)**: Examples of new data generated by sampling from the latent space of the VAE.